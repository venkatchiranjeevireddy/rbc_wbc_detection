# -*- coding: utf-8 -*-
"""ML_intern_part1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JRELfA2miSeJshd0TE869JhL4bteIvDy

##Part_1
"""

!pip install ultralytics opencv-python numpy matplotlib albumentations torch torchvision

#clonning the data set
!git clone https://github.com/Shenggan/BCCD_Dataset.git

import xml.etree.ElementTree as ET
import os

class_names = ["RBC", "WBC", "Platelets"]
os.makedirs("BCCD_Dataset/labels", exist_ok=True)

def convert_xml_to_yolo(xml_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()
    img_w = int(root.find("size/width").text)
    img_h = int(root.find("size/height").text)
    txt_filename = os.path.join("BCCD_Dataset/labels", os.path.basename(xml_file).replace(".xml", ".txt"))

    with open(txt_filename, "w") as f:
        for obj in root.findall("object"):
            cls_name = obj.find("name").text
            if cls_name in class_names:
                cls_id = class_names.index(cls_name)
                bbox = obj.find("bndbox")
                xmin, ymin, xmax, ymax = map(int, [bbox.find("xmin").text, bbox.find("ymin").text, bbox.find("xmax").text, bbox.find("ymax").text])
                x_center = (xmin + xmax) / (2 * img_w)
                y_center = (ymin + ymax) / (2 * img_h)
                w = (xmax - xmin) / img_w
                h = (ymax - ymin) / img_h

                f.write(f"{cls_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\n")  # Added precision

# Get all XML files (skip hidden/system files)
xml_dir = "BCCD_Dataset/BCCD/Annotations"
xml_files = [os.path.join(xml_dir, f) for f in os.listdir(xml_dir) if f.endswith(".xml") and not f.startswith(".")]

for xml_file in xml_files:
    convert_xml_to_yolo(xml_file)

print(" Conversion to YOLO format completed successfully!")

import albumentations as A
import cv2
import os
transform = A.Compose([
    A.Rotate(limit=30, p=0.5),
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.5)
])
image_dir = "BCCD_Dataset/BCCD/JPEGImages/"
output_dir = "BCCD_Dataset/Augmented/"
os.makedirs(output_dir, exist_ok=True)
for filename in os.listdir(image_dir):
    if filename.lower().endswith((".jpg", ".jpeg", ".png")):
        img_path = os.path.join(image_dir, filename)
        image = cv2.imread(img_path)

        if image is not None:
            for i in range(3):
                augmented = transform(image=image)['image']
                base_name, ext = os.path.splitext(filename)
                aug_img_path = os.path.join(output_dir, f"{base_name}_aug{i}{ext}")
                cv2.imwrite(aug_img_path, augmented)

print("Data augmentation completed successfully!")

# Commented out IPython magic to ensure Python compatibility.

!pip install ultralytics
!git clone https://github.com/ultralytics/ultralytics.git
# %cd ultralytics
!pip install -e .
import os
import shutil
dataset_dir = "/content/BCCD_Dataset"
images_dir = os.path.join(dataset_dir, "BCCD/JPEGImages")
labels_dir = os.path.join(dataset_dir, "labels")
aug_images_dir = os.path.join(dataset_dir, "Augmented")
yolo_dataset_dir = "/content/yolo_BCCD"
os.makedirs(yolo_dataset_dir, exist_ok=True)
os.makedirs(os.path.join(yolo_dataset_dir, "train/images"), exist_ok=True)
os.makedirs(os.path.join(yolo_dataset_dir, "train/labels"), exist_ok=True)
for img_file in os.listdir(images_dir):
    if img_file.endswith((".jpg", ".png")):
        shutil.copy(os.path.join(images_dir, img_file), os.path.join(yolo_dataset_dir, "train/images", img_file))

for img_file in os.listdir(aug_images_dir):
    if img_file.endswith((".jpg", ".png")):
        shutil.copy(os.path.join(aug_images_dir, img_file), os.path.join(yolo_dataset_dir, "train/images", img_file))
for label_file in os.listdir(labels_dir):
    if label_file.endswith(".txt"):
        shutil.copy(os.path.join(labels_dir, label_file), os.path.join(yolo_dataset_dir, "train/labels", label_file))
yaml_content = """path: /content/yolo_BCCD
train: train/images
val: train/images

nc: 3
names: ['RBC', 'WBC', 'Platelets']
"""

with open("/content/yolo_BCCD/dataset.yaml", "w") as f:
    f.write(yaml_content)

print("Dataset preparation completed!")

# STEP 5: Train YOLOv10
from ultralytics import YOLO

model = YOLO("yolov10n.pt")  # Load YOLOv10 pre-trained model
results = model.train(
    data="/content/yolo_BCCD/dataset.yaml",  # âœ… Corrected path
    epochs=30,
    batch=8,
    imgsz=640,
    amp=True
)



# STEP 6: Save the Trained Model
model.export(format="onnx")  # Save in ONNX format (optional)
model.save("/content/yolo_BCCD/yolov10_bccd.pt")  # Save final model

print("Training Completed! Model saved as yolov10_bccd.pt")

model.export(format="onnx")

from ultralytics import YOLO
import cv2
import os
import matplotlib.pyplot as plt

# Load trained YOLO model
model_path = "/content/yolo_BCCD/yolov10_bccd.pt"
if not os.path.exists(model_path):
    raise FileNotFoundError(f"Model not found at {model_path}")

model = YOLO(model_path)

# Load an image for testing
image_path = "/content/BCCD_Dataset/BCCD/JPEGImages/BloodImage_00000.jpg"
if not os.path.exists(image_path):
    raise FileNotFoundError(f"Error: Image not found at {image_path}")

# Read and preprocess the image
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Run inference with lower confidence threshold
results = model(image, conf=0.1)  # Reduced confidence threshold

# Check if objects were detected
if not results[0].boxes:
    print("No objects detected!")
else:
    # Draw bounding boxes
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cls = int(box.cls[0])
            conf = float(box.conf[0])
            label = f"{model.names[cls]} {conf:.2f}"

            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Show the image with detections
    plt.imshow(image)
    plt.axis("off")
    plt.show()

import locale
def getpreferredencoding(do_setlocale = True):
    return "UTF-8"
locale.getpreferredencoding = getpreferredencoding
!apt-get update
!apt-get install -y locales
!locale-gen en_US.UTF-8
!update-locale LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8

!pip install gradio streamlit

import gradio as gr
import cv2
import numpy as np
from ultralytics import YOLO

# Load trained YOLO model
model = YOLO("/content/yolo_BCCD/yolov10_bccd.pt")  # Ensure path is correct

# Function to make predictions
def detect_objects(image):
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert to correct format
    results = model(image, conf=0.1)

    # Draw bounding boxes
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            cls = int(box.cls[0])
            conf = float(box.conf[0])
            label = f"{model.names[cls]} {conf:.2f}"

            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert back for display

# Gradio Interface
gr.Interface(
    fn=detect_objects,
    inputs=gr.Image(type="numpy"),
    outputs=gr.Image(type="numpy"),
    title="YOLO RBC Detection",
    description="Upload an image to detect Red Blood Cells (RBCs)."
).launch(share=True)

# Commented out IPython magic to ensure Python compatibility.
!git clone https://huggingface.co/spaces/venkatchiranjeevi/yolo-rbc-detection
# %cd yolo-rbc-detection

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/ultralytics/ultralytics/yolo-rbc-detection

!mv /content/BCCD_Dataset/* /content/ultralytics/ultralytics/yolo-rbc-detection/

!git config --global user.email "bvchiranjeevi54@gmail.com"
!git config --global user.name "venkatchiranjeevi"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/ultralytics/ultralytics/yolo-rbc-detection

!git add .

!git commit -m "Added YOLO RBC Detection Project Files"

!git push